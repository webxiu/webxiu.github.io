<!DOCTYPE html>
<html lang="en">
  <head>
    <header name="Access-Control-Allow-Origin" value="*" />
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
    <title>视频抠像</title>
    <script src="../../assets/vue/vue3.global.js"></script>
    <!-- 机器学习开发库 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.1.0/dist/tf.min.js"></script>
    <!-- 机器学习模型 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0.5/dist/body-pix.min.js"></script>
    <style>
      .output {
        background: url(../assets/images/bg_mask.jpg) no-repeat center;
        width: 800px;
        height: auto;
        background-size: cover;
      }
      .bg {
        background-image: url("../assets/images/bg_mask.jpg");
      }
    </style>
  </head>

  <body>
    <div id="app">
      <!--  https://static.animpen.com/u/320/video/girl.mp4  -->
      <video ref="video" src="../assets/media/girl.mp4" anonymous muted loop autoplay controls width="800" height="450"></video>
      调节: <input type="range" min="0" max="1" step="0.05" value="0.5" @input="changeRange" />
      <div class="output">
        <canvas ref="canvas" width="800" height="450"></canvas>
      </div>
    </div>
    <script>
      const { createApp } = Vue;

      createApp({
        data() {
          return {
            range: 0.5,
          };
        },
        mounted() {
          this.init();
          bodyPix.load().then((model) => {
            this.model = model;
            this.animate();
          });
        },

        methods: {
          changeRange(e) {
            this.range = Number(e.target.value);
          },
          init() {
            this.video = this.$refs.video;
            this.canvas = this.$refs.canvas;
            this.ctx = this.canvas.getContext("2d");
            this.canvasTemp = document.createElement("canvas");
            this.canvasTemp.width = this.canvas.width;
            this.canvasTemp.height = this.canvas.height;
            this.ctxTemp = this.canvasTemp.getContext("2d");
            this.video.crossOrigin = "anonymous";
          },
          animate() {
            this.ctxTemp.drawImage(this.video, 0, 0, this.video.width, this.video.height);
            const frame = this.ctxTemp.getImageData(0, 0, this.video.width, this.video.height);
            // tf处理
            this.model.segmentPerson(this.canvasTemp, { segmentationThreshold: this.range }).then((segmentation) => {
              for (let i = 0; i < segmentation.data.length; i++) {
                if (segmentation.data[i] === 0) {
                  frame.data[i * 4 + 3] = 0;
                }
              }
              this.ctx.putImageData(frame, 0, 0);
              requestAnimationFrame(this.animate);
            });
          },
        },
      }).mount("#app");
    </script>
  </body>
</html>
